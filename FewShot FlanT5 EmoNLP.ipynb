{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-10-03T20:28:05.658705Z",
          "iopub.execute_input": "2023-10-03T20:28:05.659129Z",
          "iopub.status.idle": "2023-10-03T20:28:09.651993Z",
          "shell.execute_reply.started": "2023-10-03T20:28:05.659095Z",
          "shell.execute_reply": "2023-10-03T20:28:09.650906Z"
        },
        "trusted": true,
        "id": "UgOkxz36OC2J",
        "outputId": "87d6d8f8-a7dd-4af4-8050-8f3978845cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "/kaggle/input/train-nlp/train (1).csv\n/kaggle/input/test-nlp/test (1).csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:28:37.036548Z",
          "iopub.execute_input": "2023-10-03T20:28:37.037194Z",
          "iopub.status.idle": "2023-10-03T20:28:37.046606Z",
          "shell.execute_reply.started": "2023-10-03T20:28:37.037151Z",
          "shell.execute_reply": "2023-10-03T20:28:37.045343Z"
        },
        "trusted": true,
        "id": "KsNZkucoOC2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/train-nlp/train (1).csv')\n",
        "df_test = pd.read_csv('/kaggle/input/test-nlp/test (1).csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:28:38.878479Z",
          "iopub.execute_input": "2023-10-03T20:28:38.878891Z",
          "iopub.status.idle": "2023-10-03T20:28:38.892185Z",
          "shell.execute_reply.started": "2023-10-03T20:28:38.878854Z",
          "shell.execute_reply": "2023-10-03T20:28:38.891073Z"
        },
        "trusted": true,
        "id": "2loqhdCsOC2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans\n",
        "!pip install --upgrade googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "trusted": true,
        "id": "K0jq-LAsOC2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Augmentation"
      ],
      "metadata": {
        "id": "xJiAfQheVbWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''for data augmentation, using back translation. Converts into french first and then back to english'''\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "def back_translate(sentence, target_language='fr'):\n",
        "    translator = Translator()\n",
        "    translated = translator.translate(sentence, dest=target_language)\n",
        "    back_translated = translator.translate(translated.text, dest='en')\n",
        "    return back_translated.text\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:28:43.244375Z",
          "iopub.execute_input": "2023-10-03T20:28:43.244775Z",
          "iopub.status.idle": "2023-10-03T20:28:43.603899Z",
          "shell.execute_reply.started": "2023-10-03T20:28:43.244745Z",
          "shell.execute_reply": "2023-10-03T20:28:43.602853Z"
        },
        "trusted": true,
        "id": "2xRW9N5cOC2M",
        "outputId": "19153c30-28b3-4adb-b157-a80cbefd6211"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original: Hello, my name is Ashmit and I like ice-cream.\nBack-translated: Hello, My name is Ashmit and I like ice.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_samples = []\n",
        "\n",
        "\n",
        "for i in tqdm(range(len(df))):\n",
        "    original_text = df['Text'][i]\n",
        "    original_emotion = df['Emotion'][i]\n",
        "\n",
        "\n",
        "    translated_text = back_translate(original_text)\n",
        "\n",
        "    new_sample = {'Text': translated_text, 'Emotion': original_emotion}\n",
        "\n",
        "    new_samples.append(new_sample)\n",
        "\n",
        "new_df = pd.DataFrame(new_samples)\n",
        "\n",
        "df = pd.concat([df, new_df], ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:30:04.183467Z",
          "iopub.execute_input": "2023-10-03T20:30:04.183894Z",
          "iopub.status.idle": "2023-10-03T20:30:44.709879Z",
          "shell.execute_reply.started": "2023-10-03T20:30:04.183855Z",
          "shell.execute_reply": "2023-10-03T20:30:44.708850Z"
        },
        "trusted": true,
        "id": "HOJJrODdOC2M",
        "outputId": "c13589c3-6943-4559-bc14-322594039731"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 240/240 [00:40<00:00,  5.92it/s]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1.0, random_state=43).reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:30:48.619722Z",
          "iopub.execute_input": "2023-10-03T20:30:48.620485Z",
          "iopub.status.idle": "2023-10-03T20:30:48.627605Z",
          "shell.execute_reply.started": "2023-10-03T20:30:48.620450Z",
          "shell.execute_reply": "2023-10-03T20:30:48.626411Z"
        },
        "trusted": true,
        "id": "XxlT_DplOC2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Another library I found for dataset augmentation. Basically generates n sentences for the input sentence. the outputs are not coherent sentences but similar sentences having words with wrong spellings."
      ],
      "metadata": {
        "id": "fO56QwXsVGaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "id": "1kh2IL_EU2Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas"
      ],
      "metadata": {
        "id": "Dz9yujA-U7gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug = nac.KeyboardAug()\n",
        "augmented_text = aug.augment(text, n=2)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ],
      "metadata": {
        "id": "XHtYE4WSU_up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "new_samples = []\n",
        "\n",
        "for i in tqdm(range(len(df))):\n",
        "    original_text = df['Text'][i]\n",
        "    original_emotion = df['Emotion'][i]\n",
        "\n",
        "    for _ in range(10):\n",
        "        translated_text = aug.augment(original_text)\n",
        "\n",
        "\n",
        "        if isinstance(translated_text, list):\n",
        "            translated_text = translated_text[0]\n",
        "\n",
        "        new_sample = {'Text': translated_text, 'Emotion': original_emotion}\n",
        "\n",
        "        new_samples.append(new_sample)\n",
        "\n",
        "new_df = pd.DataFrame(new_samples)\n",
        "\n",
        "df = pd.concat([df, new_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "UbAdoofVVEDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lsyjem4IOC2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "!pip install pytesseract transformers==4.28.1 datasets evaluate rouge-score nltk tensorboard py7zr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:30:56.225669Z",
          "iopub.execute_input": "2023-10-03T20:30:56.226811Z",
          "iopub.status.idle": "2023-10-03T20:30:56.755225Z",
          "shell.execute_reply.started": "2023-10-03T20:30:56.226766Z",
          "shell.execute_reply": "2023-10-03T20:30:56.754212Z"
        },
        "trusted": true,
        "id": "oyvxuz8fOC2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from datasets import load_dataset\n",
        "import datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:01.376147Z",
          "iopub.execute_input": "2023-10-03T20:31:01.376544Z",
          "iopub.status.idle": "2023-10-03T20:31:01.656422Z",
          "shell.execute_reply.started": "2023-10-03T20:31:01.376515Z",
          "shell.execute_reply": "2023-10-03T20:31:01.655366Z"
        },
        "trusted": true,
        "id": "nduoeP5aOC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Flan T5 - Gave 70 on public leaderboard. lr = 2e-4, epochs 2, dataset size 480 rows"
      ],
      "metadata": {
        "id": "wz-6cQuUPcAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_id=\"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:04.131741Z",
          "iopub.execute_input": "2023-10-03T20:31:04.133486Z",
          "iopub.status.idle": "2023-10-03T20:31:04.352798Z",
          "shell.execute_reply.started": "2023-10-03T20:31:04.133438Z",
          "shell.execute_reply": "2023-10-03T20:31:04.351585Z"
        },
        "trusted": true,
        "id": "DacZ6m12OC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "trusted": true,
        "id": "DToIFZ9ZOC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Emotion', axis = 1, inplace = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "GPGzniEqOC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = tokenizer('Hello world')\n",
        "input"
      ],
      "metadata": {
        "trusted": true,
        "id": "EM0je_s0OC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "agEj93ctOC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/kaggle/input/test-nlp/test (1).csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "3U104lU-OC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "trusted": true,
        "id": "xkdp9QrGOC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "NaByl0u-OC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "'''label_to_text = {\n",
        "    0: 'sadness',\n",
        "    1: 'anger',\n",
        "    2: 'joy',\n",
        "    3: 'love',\n",
        "    4: 'surprise',\n",
        "    5: 'fear'\n",
        "}'''\n",
        "\n",
        "#converting to dict\n",
        "data_dict = {\n",
        "    \"text\": df['Text'].tolist(),\n",
        "    \"label\": df['Emotion'].tolist()\n",
        "}\n",
        "\n",
        "test_dict = {\n",
        "    \"text\": df_test['Text'].tolist()\n",
        "}\n",
        "\n",
        "\n",
        "dataset = Dataset.from_dict(data_dict)\n",
        "testset = Dataset.from_dict(test_dict)\n",
        "\n",
        "print(dataset[49])\n",
        "print(testset[209])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:11.274527Z",
          "iopub.execute_input": "2023-10-03T20:31:11.274956Z",
          "iopub.status.idle": "2023-10-03T20:31:11.295593Z",
          "shell.execute_reply.started": "2023-10-03T20:31:11.274924Z",
          "shell.execute_reply": "2023-10-03T20:31:11.294398Z"
        },
        "trusted": true,
        "id": "5Fb_e-aZOC2N",
        "outputId": "501743ce-a5ed-4225-eca1-76ad2c401569"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'text': 'I train every morning before and I feel fabulous for that', 'label': 'joy'}\n{'text': 'i feel kinda strange too cause i didnt encountered with such feelings last year'}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "trusted": true,
        "id": "WnC2Nl7rOC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "# The maximum total input sequence length after tokenization.\n",
        "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
        "tokenized_inputs = dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n",
        "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
        "print(f\"Max source length: {max_source_length}\")\n",
        "\n",
        "# The maximum total sequence length for target text after tokenization.\n",
        "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
        "tokenized_targets = dataset.map(lambda x: tokenizer(x[\"label\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n",
        "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
        "print(f\"Max target length: {max_target_length}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:14.210855Z",
          "iopub.execute_input": "2023-10-03T20:31:14.211501Z",
          "iopub.status.idle": "2023-10-03T20:31:14.371657Z",
          "shell.execute_reply.started": "2023-10-03T20:31:14.211450Z",
          "shell.execute_reply": "2023-10-03T20:31:14.370594Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "79bf496204bf4b64af1b9fbdfff0e8b9",
            "5c5b05c2f50b4dc3a63517dc71001368"
          ]
        },
        "id": "w3NGJ-ZQOC2O",
        "outputId": "7cf5a306-b6ba-4d5d-d9ee-873510c60ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79bf496204bf4b64af1b9fbdfff0e8b9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Max source length: 53\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c5b05c2f50b4dc3a63517dc71001368"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Max target length: 2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(sample, padding=\"max_length\"):\n",
        "    # adding prefix to the input for t5\n",
        "    inputs = [item for item in sample[\"text\"]]\n",
        "\n",
        "    # tokenizing inputs\n",
        "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
        "\n",
        "    # Tokenizing targets with the `text_target` keyword argument\n",
        "    labels = tokenizer(text_target=sample[\"label\"], max_length=max_target_length, padding=padding, truncation=True)\n",
        "\n",
        "    # If we are padding here, we replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
        "    # padding in the loss.\n",
        "    if padding == \"max_length\":\n",
        "        labels[\"input_ids\"] = [\n",
        "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
        "        ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['text', 'label'])\n",
        "print(f\"Keys of tokenized dataset: {list(tokenized_dataset.features)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:16.644531Z",
          "iopub.execute_input": "2023-10-03T20:31:16.644951Z",
          "iopub.status.idle": "2023-10-03T20:31:16.730468Z",
          "shell.execute_reply.started": "2023-10-03T20:31:16.644918Z",
          "shell.execute_reply": "2023-10-03T20:31:16.729444Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "de30a72d23494df9ae9f86488dc2fbf3"
          ]
        },
        "id": "_2_HYJA9OC2O",
        "outputId": "bee30dc5-ee9d-4428-bec2-1ad0d2d7e6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de30a72d23494df9ae9f86488dc2fbf3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "trusted": true,
        "id": "A_Fq6hE5OC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U accelerate"
      ],
      "metadata": {
        "trusted": true,
        "id": "AXYoH4FMOC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model_id=\"google/flan-t5-base\"\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:22.743269Z",
          "iopub.execute_input": "2023-10-03T20:31:22.743654Z",
          "iopub.status.idle": "2023-10-03T20:31:26.392624Z",
          "shell.execute_reply.started": "2023-10-03T20:31:22.743627Z",
          "shell.execute_reply": "2023-10-03T20:31:26.391445Z"
        },
        "trusted": true,
        "id": "VxTmFsCyOC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "metric = evaluate.load(\"f1\")\n",
        "\n",
        "#preprocessing\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, average='macro')\n",
        "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:30.689760Z",
          "iopub.execute_input": "2023-10-03T20:31:30.690198Z",
          "iopub.status.idle": "2023-10-03T20:31:32.388196Z",
          "shell.execute_reply.started": "2023-10-03T20:31:30.690170Z",
          "shell.execute_reply": "2023-10-03T20:31:32.387010Z"
        },
        "trusted": true,
        "id": "S9vzxoOnOC2O",
        "outputId": "e4cca33f-4cfe-46da-b420-2bb93e54a531"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# we want to ignore tokenizer pad token in the loss\n",
        "label_pad_token_id = -100\n",
        "# Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=label_pad_token_id,\n",
        "    pad_to_multiple_of=8\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:31:37.981376Z",
          "iopub.execute_input": "2023-10-03T20:31:37.981771Z",
          "iopub.status.idle": "2023-10-03T20:31:37.987210Z",
          "shell.execute_reply.started": "2023-10-03T20:31:37.981740Z",
          "shell.execute_reply": "2023-10-03T20:31:37.986129Z"
        },
        "trusted": true,
        "id": "A1JDY1CDOC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C_lJ6fl7ShgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from huggingface_hub import HfFolder\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "repository_id = f\"{model_id.split('/')[1]}-imdb-text-classification\"\n",
        "\n",
        "# training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=repository_id,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False, # Overflows with fp16\n",
        "    learning_rate=2e-4,\n",
        "\n",
        "    num_train_epochs=2,\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"tensorboard\",\n",
        "    hub_strategy=\"every_save\",\n",
        "    hub_model_id=repository_id,\n",
        "    hub_token=HfFolder.get_token(),\n",
        ")\n",
        "\n",
        "# trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:34:02.886089Z",
          "iopub.execute_input": "2023-10-03T20:34:02.886498Z",
          "iopub.status.idle": "2023-10-03T20:34:02.904350Z",
          "shell.execute_reply.started": "2023-10-03T20:34:02.886466Z",
          "shell.execute_reply": "2023-10-03T20:34:02.902930Z"
        },
        "trusted": true,
        "id": "XZ8ucIazOC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:34:03.594049Z",
          "iopub.execute_input": "2023-10-03T20:34:03.594446Z",
          "iopub.status.idle": "2023-10-03T20:34:48.375382Z",
          "shell.execute_reply.started": "2023-10-03T20:34:03.594416Z",
          "shell.execute_reply": "2023-10-03T20:34:48.374188Z"
        },
        "trusted": true,
        "id": "b4qQAfgfOC2O",
        "outputId": "675faa36-330e-4742-deac-88ec9b70db00"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [120/120 00:44, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>60</td>\n      <td>0.317400</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.018200</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=120, training_loss=0.16778303682804108, metrics={'train_runtime': 44.7407, 'train_samples_per_second': 21.457, 'train_steps_per_second': 2.682, 'total_flos': 71899522007040.0, 'train_loss': 0.16778303682804108, 'epoch': 2.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "samples_number = len(testset)\n",
        "progress_bar = tqdm(range(samples_number))\n",
        "predictions_list = []\n",
        "labels_list = []\n",
        "for i in range(samples_number):\n",
        "    text = testset['text'][i]\n",
        "    inputs = tokenizer.encode_plus(text, padding='max_length', max_length=512, return_tensors='pt').to('cuda')\n",
        "    outputs = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=150, num_beams=4, early_stopping=True)\n",
        "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    predictions_list.append(prediction)\n",
        "    #labels_list.append(dataset['test']['label'][i])\n",
        "\n",
        "    progress_bar.update(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:34:52.598385Z",
          "iopub.execute_input": "2023-10-03T20:34:52.598780Z",
          "iopub.status.idle": "2023-10-03T20:35:10.477854Z",
          "shell.execute_reply.started": "2023-10-03T20:34:52.598749Z",
          "shell.execute_reply": "2023-10-03T20:35:10.476727Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "d1257cad96264dfe864e1c5850aed4a0"
          ]
        },
        "id": "DZXvhfirOC2O",
        "outputId": "db532956-e48e-4905-ec74-e0910fe995e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/210 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1257cad96264dfe864e1c5850aed4a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_list = pd.DataFrame(predictions_list)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:35:16.938547Z",
          "iopub.execute_input": "2023-10-03T20:35:16.938994Z",
          "iopub.status.idle": "2023-10-03T20:35:16.945152Z",
          "shell.execute_reply.started": "2023-10-03T20:35:16.938961Z",
          "shell.execute_reply": "2023-10-03T20:35:16.943862Z"
        },
        "trusted": true,
        "id": "Qdw0deYWOC2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.concat([df_test, predictions_list], ignore_index=True, axis = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:35:18.528088Z",
          "iopub.execute_input": "2023-10-03T20:35:18.528504Z",
          "iopub.status.idle": "2023-10-03T20:35:18.535135Z",
          "shell.execute_reply.started": "2023-10-03T20:35:18.528473Z",
          "shell.execute_reply": "2023-10-03T20:35:18.533655Z"
        },
        "trusted": true,
        "id": "g8RfqR1ROC2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = df_1.rename(columns={0: 'ID', 1: 'Text', 2: 'Emotion'})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:35:19.031846Z",
          "iopub.execute_input": "2023-10-03T20:35:19.032633Z",
          "iopub.status.idle": "2023-10-03T20:35:19.039558Z",
          "shell.execute_reply.started": "2023-10-03T20:35:19.032596Z",
          "shell.execute_reply": "2023-10-03T20:35:19.038252Z"
        },
        "trusted": true,
        "id": "q3TkCAa6OC2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.drop('Text', axis = 1, inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:35:19.777165Z",
          "iopub.execute_input": "2023-10-03T20:35:19.777555Z",
          "iopub.status.idle": "2023-10-03T20:35:19.784261Z",
          "shell.execute_reply.started": "2023-10-03T20:35:19.777525Z",
          "shell.execute_reply": "2023-10-03T20:35:19.783128Z"
        },
        "trusted": true,
        "id": "VvqV8MgPOC2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:35:26.717031Z",
          "iopub.execute_input": "2023-10-03T20:35:26.717425Z",
          "iopub.status.idle": "2023-10-03T20:35:26.734605Z",
          "shell.execute_reply.started": "2023-10-03T20:35:26.717394Z",
          "shell.execute_reply": "2023-10-03T20:35:26.733322Z"
        },
        "trusted": true,
        "id": "CIW9IhK7OC2P",
        "outputId": "2bfa1630-65f8-4462-e865-bfc197a394b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      ID   Emotion\n0      0       joy\n1      1     anger\n2      2   sadness\n3      3      love\n4      4       joy\n..   ...       ...\n205  205  surprise\n206  206  surprise\n207  207  surprise\n208  208   sadness\n209  209  surprise\n\n[210 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>205</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>206</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>207</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>208</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>209</td>\n      <td>surprise</td>\n    </tr>\n  </tbody>\n</table>\n<p>210 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.to_csv('predicted_results_23_nlp.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T20:35:34.135031Z",
          "iopub.execute_input": "2023-10-03T20:35:34.135432Z",
          "iopub.status.idle": "2023-10-03T20:35:34.143921Z",
          "shell.execute_reply.started": "2023-10-03T20:35:34.135402Z",
          "shell.execute_reply": "2023-10-03T20:35:34.142783Z"
        },
        "trusted": true,
        "id": "8dsmSFnUOC2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bert gave 52 on public leader board. lr 1e-5, 120, 6 epochs"
      ],
      "metadata": {
        "id": "xBK5ZJGNP156"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "U4ELbIdgP03Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "#mapping\n",
        "label_to_text = {\n",
        "    0: 'sadness',\n",
        "    1: 'anger',\n",
        "    2: 'joy',\n",
        "    3: 'love',\n",
        "    4: 'surprise',\n",
        "    5: 'fear'\n",
        "}\n",
        "\n",
        "df['label_text'] = df['Emotion'].map({v: k for k, v in label_to_text.items()})\n",
        "\n",
        "# converting to a dictionary format.\n",
        "data_dict = {\n",
        "    \"text\": df['Text'].tolist(),\n",
        "    \"label\": df['label_text'].tolist(),\n",
        "    \"label_text\": df['Emotion'].tolist()\n",
        "}\n",
        "\n",
        "test_dict = {\n",
        "    \"text\": df_test['Text'].tolist()\n",
        "}\n",
        "\n",
        "\n",
        "dataset = Dataset.from_dict(data_dict)\n",
        "testset = Dataset.from_dict(test_dict)\n",
        "\n",
        "print(dataset[49])\n",
        "print(testset[209])\n"
      ],
      "metadata": {
        "id": "PIn6LiBGRvfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = dataset.map(tokenize, batched=True, batch_size=None)\n",
        "emotions_encoded_test = testset.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0cvxo8_mOC2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('tf',\n",
        "                            columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def order(inp):\n",
        "    data = list(inp.values())\n",
        "    return {\n",
        "        'input_ids': data[1],\n",
        "        'attention_mask': data[2],\n",
        "        'token_type_ids': data[3]\n",
        "    }, data[0]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded[:])\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n",
        "train_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded_test[:])\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VQ4RmIkLOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTForClassification(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, bert_model, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bert(inputs)[1]\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "GP3Txp21OC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = BERTForClassification(model, num_classes=6)\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "K_nfiYjkOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier.fit(\n",
        "    train_dataset,\n",
        "    epochs=3\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MHvafeJXOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = classifier.predict(test_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tCHKX2kuOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_text = {\n",
        "    0: 'sadness',\n",
        "    1: 'anger',\n",
        "    2: 'joy',\n",
        "    3: 'love',\n",
        "    4: 'surprise',\n",
        "    5: 'fear'\n",
        "}\n",
        "\n",
        "predicted_labels = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "3BjivgpIOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels"
      ],
      "metadata": {
        "trusted": true,
        "id": "4fYXIf7FOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label_texts = [label_to_text[label] for label in predicted_labels]\n",
        "\n",
        "df_test['Emotion'] = predicted_label_texts"
      ],
      "metadata": {
        "trusted": true,
        "id": "VsNBnz4_OC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.drop('Text', axis=1, inplace = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "yZqiBmYVOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_csv('predicted_results_17_nlp.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "58Q5n4TVOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.0.1"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dhnghd1aOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setfit gave 43 on public leaderboard. Didnt get time to finetune and check for different hps."
      ],
      "metadata": {
        "id": "WGF789YlQNda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/pmbaumgartner/setfit -q"
      ],
      "metadata": {
        "trusted": true,
        "id": "xrfZDCAxOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from setfit import SetFitClassifier"
      ],
      "metadata": {
        "trusted": true,
        "id": "l2UEGs6wOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SetFitClassifier(\"paraphrase-MiniLM-L3-v2\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "W8lcx6rTOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_form = df"
      ],
      "metadata": {
        "trusted": true,
        "id": "s8daXdKrOC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_form['Emotion_label'] = pd.DataFrame(train_form['Emotion'].replace('fear',0).replace('surprise',1).replace('sadness',2).replace('joy',3).replace('anger',4).replace('love',5))"
      ],
      "metadata": {
        "trusted": true,
        "id": "53a0o6uPOC2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = train_form['Text'].to_list()\n",
        "labels = train_form['Emotion'].to_list()"
      ],
      "metadata": {
        "trusted": true,
        "id": "uccd9QRCOC2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(docs, labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RpKOk_rZOC2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/kaggle/input/train-nlp/test (1).csv')"
      ],
      "metadata": {
        "id": "VZykxjtdOC2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['Emotion'] = clf.predict(df_test['Text'].to_list())"
      ],
      "metadata": {
        "trusted": true,
        "id": "pyEai3RpOC2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.drop('Text', axis = 1, inplace = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "jQFr6tysOC2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_csv('predicted_results_18_nlp.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vGItIZVAOC2V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}